{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from KNNbaseline import KNNbase_Unlearning\n",
    "from surprise import dump\n",
    "from KnnPred import knnpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "prediction accuracy is: 0.8176422983544646\n",
      "accuracy of shard0 shuffled: 0.8176422983544646\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "shard0\n",
    "shuffle == True\n",
    "'''\n",
    "\n",
    "KNN_Unl = KNNbase_Unlearning(shuffle=True)\n",
    "# data_df = KNN_Unl.data_readin('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "data_df = KNN_Unl.data_readin('../../data/shards_5_shuffled/dataset_sharded0.csv')\n",
    "algorithm = KNN_Unl.train_model()\n",
    "dump.dump(\"../../model/shards_5_shuffled/shard0-trainedmodel.m\", algo=algorithm)\n",
    "# KNN_Unl.get_similar_users_recommendations(algorithm, '7', 10)\n",
    "KNN_Unl.data_df.to_csv(\"../../data/shards_5_shuffled/u-unlearning0.csv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "_, algo = dump.load(\"../../model/shards_5_shuffled/shard0-trainedmodel.m\")\n",
    "\n",
    "Pred = knnpred(algo=algo, shuffle=True) # transmit into class knnpred and output accuracy\n",
    "acc = Pred.calculate_accuracy()\n",
    "print('accuracy of shard0 shuffled: {}'.format(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "prediction accuracy is: 0.8054104727467524\n",
      "accuracy of shard0 ordered: 0.8054104727467524\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "shard0\n",
    "shuffle == False\n",
    "'''\n",
    "\n",
    "KNN_Unl = KNNbase_Unlearning(shuffle=False)\n",
    "# data_df = KNN_Unl.data_readin('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "data_df = KNN_Unl.data_readin('../../data/shards_5_ordered/dataset_sharded0.csv')\n",
    "algorithm = KNN_Unl.train_model()\n",
    "dump.dump(\"../../model/shards_5_ordered/shard0-trainedmodel.m\", algo=algorithm)\n",
    "# KNN_Unl.get_similar_users_recommendations(algorithm, '7', 10)\n",
    "KNN_Unl.data_df.to_csv(\"../../data/shards_5_ordered/u-unlearning0.csv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "_, algo = dump.load(\"../../model/shards_5_ordered/shard0-trainedmodel.m\")\n",
    "\n",
    "Pred = knnpred(algo=algo, shuffle=False) # transmit into class knnpred and output accuracy\n",
    "acc = Pred.calculate_accuracy()\n",
    "print('accuracy of shard0 ordered: {}'.format(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "recommendations for user 7:\n",
      "Secrets & Lies (1996)\n",
      "Cold Comfort Farm (1995)\n",
      "Antonia's Line (1995)\n",
      "L.A. Confidential (1997)\n",
      "Titanic (1997)\n",
      "Fargo (1996)\n",
      "As Good As It Gets (1997)\n",
      "Angels and Insects (1995)\n",
      "Deconstructing Harry (1997)\n",
      "Good Will Hunting (1997)\n",
      "[Prediction(uid='7', iid='144', r_ui=5, est=4.471712531142465, details={'actual_k': 40, 'was_impossible': False}), Prediction(uid='7', iid='211', r_ui=5, est=4.558248438220909, details={'actual_k': 40, 'was_impossible': False}), Prediction(uid='7', iid='569', r_ui=4, est=3.2831914790346515, details={'actual_k': 40, 'was_impossible': False})]\n",
      "user: 7          item: 144        r_ui = 5.00   est = 4.47   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 7          item: 211        r_ui = 5.00   est = 4.56   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 7          item: 569        r_ui = 4.00   est = 3.28   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "full trained not sharded\n",
    "shuffle == False\n",
    "\"\"\"\n",
    "\n",
    "KNN_Unl = KNNbase_Unlearning(shuffle=False)\n",
    "data_df = KNN_Unl.data_readin('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "algorithm = KNN_Unl.train_model()\n",
    "dump.dump(\"../model/sharding_test/fulldataset-trainedmodel.m\", algo=algorithm)\n",
    "KNN_Unl.get_similar_users_recommendations(algorithm, '7', 10)\n",
    "KNN_Unl.data_df.to_csv(\"../data/sharding_test/fulltrain-unlearning0.csv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "_, algo = dump.load(\"../model/sharding_test/fulldataset-trainedmodel.m\")\n",
    "'''\n",
    "7\t144\t5\t891351201\n",
    "7\t211\t5\t891352557\n",
    "7\t569\t4\t892131978\n",
    "'''\n",
    "\n",
    "testset =  [\n",
    "    ('7','144',5),# 想获取第5个用户对第1个item的得分\n",
    "    ('7','211',5),# 0这个位置是真实得分，不知道时可以写0\n",
    "    ('7','569',4),# 但写0后，就没法进行算法评估了，因为不知道真实值\n",
    "]\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "print(predictions)\n",
    "for i in predictions:\n",
    "    print(i)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "[Prediction(uid='7', iid='144', r_ui=5, est=4.471712531142465, details={'actual_k': 40, 'was_impossible': False}), Prediction(uid='7', iid='211', r_ui=5, est=4.558248438220909, details={'actual_k': 40, 'was_impossible': False}), Prediction(uid='7', iid='569', r_ui=4, est=3.2831914790346515, details={'actual_k': 40, 'was_impossible': False})]\n",
      "user: 7          item: 144        r_ui = 5.00   est = 4.47   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 7          item: 211        r_ui = 5.00   est = 4.56   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 7          item: 569        r_ui = 4.00   est = 3.28   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "full trained not sharded\n",
    "shuffle == True\n",
    "\"\"\"\n",
    "\n",
    "KNN_Unl = KNNbase_Unlearning(shuffle=True)\n",
    "data_df = KNN_Unl.data_readin('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "algorithm = KNN_Unl.train_model()\n",
    "dump.dump(\"../model/sharding_test/fulldataset-trainedmodel.m\", algo=algorithm)\n",
    "KNN_Unl.get_similar_users_recommendations(algorithm, '7', 10)\n",
    "KNN_Unl.data_df.to_csv(\"../data/sharding_test/fulltrain-unlearning0.csv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "_, algo = dump.load(\"../model/sharding_test/fulldataset-trainedmodel.m\")\n",
    "'''\n",
    "7\t144\t5\t891351201\n",
    "7\t211\t5\t891352557\n",
    "7\t569\t4\t892131978\n",
    "'''\n",
    "\n",
    "testset =  [\n",
    "    ('7','144',5),# 想获取第5个用户对第1个item的得分\n",
    "    ('7','211',5),# 0这个位置是真实得分，不知道时可以写0\n",
    "    ('7','569',4),# 但写0后，就没法进行算法评估了，因为不知道真实值\n",
    "]\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "print(predictions)\n",
    "for i in predictions:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "  user item rating  timestamp\n",
      "0  201  179      5  884114471\n",
      "1  201  218      4  884114471\n",
      "2  201  506      4  884114471\n",
      "3  201   55      4  884114471\n",
      "4  201  767      4  884114505\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "None\n",
      "<surprise.prediction_algorithms.knns.KNNBaseline object at 0x000001AFB7A9A550>\n",
      "[Prediction(uid='7', iid='144', r_ui=5, est=3.8653109844997977, details={'was_impossible': False}), Prediction(uid='7', iid='211', r_ui=5, est=4.0594333920330214, details={'was_impossible': False}), Prediction(uid='7', iid='569', r_ui=4, est=3.2969364023268475, details={'was_impossible': False})]\n",
      "user: 7          item: 144        r_ui = 5.00   est = 3.87   {'was_impossible': False}\n",
      "user: 7          item: 211        r_ui = 5.00   est = 4.06   {'was_impossible': False}\n",
      "user: 7          item: 569        r_ui = 4.00   est = 3.30   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "shard1\n",
    "shuffle == False\n",
    "'''\n",
    "shards = 5\n",
    "models = [_ for _ in range(shards)]\n",
    "print(models)\n",
    "\n",
    "KNN_Unl = KNNbase_Unlearning()\n",
    "# data_df = KNN_Unl.data_readin('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "KNN_Unl.data_readin('../../data/shards_5_ordered/dataset_sharded1.csv')\n",
    "print(KNN_Unl.data_df.head())\n",
    "algorithm = KNN_Unl.train_model()\n",
    "dump.dump(\"../../model/shards_5_ordered/shard1_trainedmodel.m\", algo=algorithm)\n",
    "# KNN_Unl.get_similar_users_recommendations(algorithm, '7', 10)\n",
    "KNN_Unl.data_df.to_csv(\"../../data/sharding_test/shard1-unlearning0.csv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "_, models[0] = dump.load(\"../../model/shards_5_ordered/shard1_trainedmodel.m\")\n",
    "print(_)\n",
    "print(models[0])\n",
    "'''\n",
    "7\t144\t5\t891351201\n",
    "7\t211\t5\t891352557\n",
    "7\t569\t4\t892131978\n",
    "'''\n",
    "\n",
    "testset =  [\n",
    "    ('7','144',5),# 想获取第5个用户对第1个item的得分\n",
    "    ('7','211',5),# 0这个位置是真实得分，不知道时可以写0\n",
    "    ('7','569',4),# 但写0后，就没法进行算法评估了，因为不知道真实值\n",
    "]\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "print(predictions)\n",
    "for i in predictions:\n",
    "    print(i)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "history_index = [1]\n",
    "print(isinstance(history_index, list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../model/shards_5_shuffled/sharded_trained_model0.m'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_40144/3695283670.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mmodels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0m_\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshards\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshards\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"../../model/shards_{}_{}/sharded_trained_model{}.m\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshards\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshuflled_ordered_str\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mPred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mknnpred\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0malgo\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\conda\\Anaconda3\\envs\\myju\\lib\\site-packages\\surprise\\dump.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(file_name)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \"\"\"\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m     \u001B[0mdump_obj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdump_obj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'predictions'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdump_obj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'algo'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../model/shards_5_shuffled/sharded_trained_model0.m'"
     ]
    }
   ],
   "source": [
    "from KnnPred import knnpred \n",
    "\n",
    "shuffle = True\n",
    "shards = 5\n",
    "shuflled_ordered_str = 'shuffled' if shuffle else 'ordered'\n",
    "models = [_ for _ in range(shards)]\n",
    "for s in range(shards):\n",
    "    _, models[s] = dump.load(\"../../model/shards_{}_{}/sharded_trained_model{}.m\".format(shards, shuflled_ordered_str, s))\n",
    "\n",
    "Pred = knnpred(algo=models[0], shuffle=shuffle)\n",
    "testlist = Pred.get_testlist()\n",
    "preds = [_ for _ in range(shards)]\n",
    "for s in range(shards):\n",
    "    Pred = knnpred(algo=models[s], shuffle=shuffle)  # transmit into class knnpred and output accuracy\n",
    "    acc, preds[s] = Pred.calculate_accuracy()\n",
    "    print('accuracy of shard{} shuffled: {}'.format(s, acc))\n",
    "\n",
    "print(preds)\n",
    "print(len(preds))\n",
    "# print(len(preds[0]))\n",
    "# print(len(preds[1]))\n",
    "# print(len(preds[2]))\n",
    "# print(len(preds[3]))\n",
    "# print(len(preds[4]))\n",
    "print(len(testlist))\n",
    "\n",
    "print(preds[0])\n",
    "print(preds[1])\n",
    "print(preds[2])\n",
    "print(preds[3])\n",
    "print(preds[4])\n",
    "print(testlist)\n",
    "\n",
    "bagginglist = []\n",
    "for i in range(len(testlist)):\n",
    "    cnt = 0 # static 1s number\n",
    "    for j in range(5):\n",
    "        if preds[j][i] == 1: cnt += 1\n",
    "    if cnt >= 3: bagginglist.append(1)\n",
    "    else: bagginglist.append(0)\n",
    "\n",
    "hits = 0\n",
    "for i in range(len(testlist)):\n",
    "    if bagginglist[i] == testlist[i]:\n",
    "        hits += 1\n",
    "acc = hits / len(testlist)\n",
    "print('bagging model accuracy: {}'.format(acc))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (surprise-recommendation)",
   "language": "python",
   "name": "pycharm-1f44e0f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}